{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vuhung16au/KidsLearnsAlgorithms/blob/main/Supercharge_Your_Data_Preprocessing_with_Numba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_Kca1RBYQWH9",
        "outputId": "c1e63c33-d09a-4d7f-d608-2d820c6dcc3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.416228771209717 seconds\n",
            "Execution time: 7.608553647994995 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nThe @jit(nopython=True) decorator compiles the function to machine code. \\nThe nopython mode ensures maximum performance.\\n\\nOverall this significantly speeds up the normalization process. \\nIt's especially beneficial for large datasets, like the million-element array used here, where standard Python loops would be slow.\\n\\n\\nNumba works best with NumPy arrays and scalar values. \\nIt doesn't support all Python features, so keep your jitted functions simple.\\n\\n\\nMeasure the performance gain using %timeit in Jupyter. \\nYou'll often see 10x to 100x speedups for suitable functions.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numba import jit\n",
        "import time\n",
        "\n",
        "# @jit(nopython=True)\n",
        "def custom_normalize(data, lower=0, upper=1):\n",
        "    min_val = np.min(data)\n",
        "    max_val = np.max(data)\n",
        "\n",
        "    numerator = (data - min_val) * (upper - lower)\n",
        "    denominator = max_val - min_val\n",
        "\n",
        "    return numerator / denominator + lower\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "data = np.random.rand(100000000)\n",
        "normalized_data = custom_normalize(data)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time} seconds\")\n",
        "\n",
        "@jit(nopython=True)\n",
        "def custom_normalize(data, lower=0, upper=1):\n",
        "    min_val = np.min(data)\n",
        "    max_val = np.max(data)\n",
        "\n",
        "    numerator = (data - min_val) * (upper - lower)\n",
        "    denominator = max_val - min_val\n",
        "\n",
        "    return numerator / denominator + lower\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "data = np.random.rand(100000000)\n",
        "normalized_data = custom_normalize(data)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time} seconds\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Numba helps you dramatically speed up NumPy operations in your data preprocessing pipeline.\n",
        "It uses just-in-time compilation to convert Python and NumPy code into optimized machine code.\n",
        "\n",
        "\n",
        "You can apply Numba to CPU-bound operations that slow down your preprocessing.\n",
        "It's particularly effective for numerical algorithms and loops that can't be easily vectorized.\n",
        "\n",
        "\n",
        "Here's how to use Numba to optimize a custom data normalization function:\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "The @jit(nopython=True) decorator compiles the function to machine code.\n",
        "The nopython mode ensures maximum performance.\n",
        "\n",
        "Overall this significantly speeds up the normalization process.\n",
        "It's especially beneficial for large datasets, like the million-element array used here, where standard Python loops would be slow.\n",
        "\n",
        "\n",
        "Numba works best with NumPy arrays and scalar values.\n",
        "It doesn't support all Python features, so keep your jitted functions simple.\n",
        "\n",
        "\n",
        "Measure the performance gain using %timeit in Jupyter.\n",
        "You'll often see 10x to 100x speedups for suitable functions.\n",
        "\n",
        "\"\"\""
      ]
    }
  ]
}